<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>且炼时光</title>
  <icon>https://linshenkx.github.io/icon.png</icon>
  <subtitle>韶华未褪，且炼时光</subtitle>
  <link href="https://linshenkx.github.io/atom.xml" rel="self"/>
  
  <link href="https://linshenkx.github.io/"/>
  <updated>2021-09-13T05:05:33.318Z</updated>
  <id>https://linshenkx.github.io/</id>
  
  <author>
    <name>林泽浩</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>clash代理工具docker版使用笔记</title>
    <link href="https://linshenkx.github.io/clash_docker/"/>
    <id>https://linshenkx.github.io/clash_docker/</id>
    <published>2021-09-12T14:54:20.000Z</published>
    <updated>2021-09-13T05:05:33.318Z</updated>
    
    
    <summary type="html">&lt;p&gt;clash docker镜像使用笔记，以及常用代理配置方法&lt;/p&gt;</summary>
    
    
    
    <category term="程序员杂记" scheme="https://linshenkx.github.io/categories/%E7%A8%8B%E5%BA%8F%E5%91%98%E6%9D%82%E8%AE%B0/"/>
    
    
    <category term="生产力" scheme="https://linshenkx.github.io/tags/%E7%94%9F%E4%BA%A7%E5%8A%9B/"/>
    
    <category term="clash" scheme="https://linshenkx.github.io/tags/clash/"/>
    
    <category term="docker" scheme="https://linshenkx.github.io/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>基于k8s的家用大数据集群设计与实现</title>
    <link href="https://linshenkx.github.io/household_k8s_bigdata/"/>
    <id>https://linshenkx.github.io/household_k8s_bigdata/</id>
    <published>2021-07-13T14:54:20.000Z</published>
    <updated>2021-09-03T15:57:49.860Z</updated>
    
    
    <summary type="html">&lt;p&gt;使用3台废旧笔记本搭建k8s集群，部署大数据组件，利用路由器进行异地组网，配合wsl作为管理和客户端，&lt;br&gt;实现随时随地，在工作笔记本上以本地访问的体验使用自建家庭大数据平台进行学习、开发、测试。&lt;/p&gt;</summary>
    
    
    
    <category term="大数据" scheme="https://linshenkx.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="生产力" scheme="https://linshenkx.github.io/tags/%E7%94%9F%E4%BA%A7%E5%8A%9B/"/>
    
    <category term="大数据" scheme="https://linshenkx.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    <category term="WSL" scheme="https://linshenkx.github.io/tags/WSL/"/>
    
  </entry>
  
  <entry>
    <title>Ranger2.1编译笔记</title>
    <link href="https://linshenkx.github.io/ranger-compile/"/>
    <id>https://linshenkx.github.io/ranger-compile/</id>
    <published>2021-06-21T12:55:09.000Z</published>
    <updated>2021-09-01T08:02:17.797Z</updated>
    
    
    <summary type="html">&lt;p&gt;本文记录了 ranger2.1版本的编译过程，与遇到的一些bug的解决方法。&lt;/p&gt;</summary>
    
    
    
    <category term="ranger" scheme="https://linshenkx.github.io/categories/ranger/"/>
    
    
  </entry>
  
  <entry>
    <title>WSL2配置与结合IDEA2021使用体验</title>
    <link href="https://linshenkx.github.io/wsl2_idea2021/"/>
    <id>https://linshenkx.github.io/wsl2_idea2021/</id>
    <published>2021-04-13T14:54:20.000Z</published>
    <updated>2021-09-13T04:49:17.814Z</updated>
    
    
    <summary type="html">&lt;p&gt;最近把IDEA更新到了2021，发现新版本增强了对WSL2的支持。之前的WSL2很鸡肋，吹很厉害，但真要开发又很不方便。 本来还想等着windows增强WSL2对gui的支持，然后在WSL2里装个IDEA。&lt;br&gt;倒是IDEA动作快一点，先做了支持。不错，值得捣鼓一番。之前为了gui把wsl环境弄得很混乱，直接重装，随便记录一下操作。&lt;/p&gt;</summary>
    
    
    
    <category term="程序员杂记" scheme="https://linshenkx.github.io/categories/%E7%A8%8B%E5%BA%8F%E5%91%98%E6%9D%82%E8%AE%B0/"/>
    
    
    <category term="生产力" scheme="https://linshenkx.github.io/tags/%E7%94%9F%E4%BA%A7%E5%8A%9B/"/>
    
    <category term="WSL" scheme="https://linshenkx.github.io/tags/WSL/"/>
    
  </entry>
  
  <entry>
    <title>大数据通用计算平台(支持flink、spark等)(1)系统调研及设计</title>
    <link href="https://linshenkx.github.io/bigdata_compute_platform/"/>
    <id>https://linshenkx.github.io/bigdata_compute_platform/</id>
    <published>2021-01-09T13:08:41.000Z</published>
    <updated>2021-09-01T08:02:17.798Z</updated>
    
    
    <summary type="html">&lt;p&gt;项目源于对flink_sql流计算任务的实际使用需求，最初目标是设计一个系统可以在线提交sql生成flink流式计算任务，并进行监控监测。 后延申至支持在线jar包提交的方式，同时支持批式计算任务。并以模块化开发的思路，引入对spark的支持。&lt;/p&gt;</summary>
    
    
    
    <category term="大数据" scheme="https://linshenkx.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="flink" scheme="https://linshenkx.github.io/tags/flink/"/>
    
    <category term="spark" scheme="https://linshenkx.github.io/tags/spark/"/>
    
  </entry>
  
  <entry>
    <title>hive使用bulkLoad批量导入数据到hbase</title>
    <link href="https://linshenkx.github.io/hive_bulkLoad_hbase/"/>
    <id>https://linshenkx.github.io/hive_bulkLoad_hbase/</id>
    <published>2020-11-23T14:49:02.000Z</published>
    <updated>2021-09-01T08:02:17.795Z</updated>
    
    
    <summary type="html">&lt;p&gt;本文主要参考了hbase和hive官方文档的说明，并结合cdh和hdp的一些教程以及个人在生产中的实践进行记录。主要内容有hbase bulkload的原理以及对应hive的操作步骤，最后基于cdh进行完整实验提供参考实例。&lt;br&gt;不过整个操作确实很复杂繁琐，不是很建议使用。现在有挺多使用Spark Bulkload，下次有机会尝试一下。&lt;br&gt;之前是遇到一个需求，源表在hbase上，需要重新生成rowkey并提取部分字段形成新表。功能很简单，就是行对行映射过去，但是效率太低耗时太长，用bulkload确实解决了当时的麻烦。&lt;br&gt;写这篇文章是对自己操作的复盘，同时也梳理一下知识。&lt;br&gt;实验环境为：CDH6.3.2，对应的各个组件版本为：hadoop3.0.0，hbase2.1.0，hive2.1.1&lt;/p&gt;</summary>
    
    
    
    <category term="大数据" scheme="https://linshenkx.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="hbase" scheme="https://linshenkx.github.io/tags/hbase/"/>
    
    <category term="hive" scheme="https://linshenkx.github.io/tags/hive/"/>
    
    <category term="bulkload" scheme="https://linshenkx.github.io/tags/bulkload/"/>
    
  </entry>
  
  <entry>
    <title>hive编写udf实践记录</title>
    <link href="https://linshenkx.github.io/hive_udf/"/>
    <id>https://linshenkx.github.io/hive_udf/</id>
    <published>2020-11-10T15:47:22.000Z</published>
    <updated>2021-09-01T08:02:17.796Z</updated>
    
    
    <summary type="html">&lt;p&gt;官方教程：&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/HivePlugins&quot;&gt;https://cwiki.apache.org/confluence/display/Hive/HivePlugins&lt;/a&gt;&lt;br&gt;简单使用查看上面官方的文档即可。这里记录一下我使用的实践和一点注意事项。&lt;/p&gt;</summary>
    
    
    
    <category term="大数据" scheme="https://linshenkx.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="hive" scheme="https://linshenkx.github.io/tags/hive/"/>
    
  </entry>
  
  <entry>
    <title>CDH客户端环境搭建</title>
    <link href="https://linshenkx.github.io/cdh_client_env_deploy/"/>
    <id>https://linshenkx.github.io/cdh_client_env_deploy/</id>
    <published>2020-11-10T13:51:20.000Z</published>
    <updated>2021-09-01T08:02:17.793Z</updated>
    
    
    <summary type="html">&lt;p&gt;最近遇到一个需求：要使用azkaban对接客户的CDH集群，CDH用的是oozie，azkaban只能部署在我们客户端的机器上，所以需要在客户机上手动搭建CDH的hadoop环境。操作很简单，过程比较麻烦，这里记录一下。&lt;/p&gt;</summary>
    
    
    
    <category term="大数据" scheme="https://linshenkx.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="CDH" scheme="https://linshenkx.github.io/tags/CDH/"/>
    
  </entry>
  
  <entry>
    <title>CDH部署笔记</title>
    <link href="https://linshenkx.github.io/cdh_server_env_deploy/"/>
    <id>https://linshenkx.github.io/cdh_server_env_deploy/</id>
    <published>2020-10-27T16:29:54.000Z</published>
    <updated>2021-09-01T08:02:17.793Z</updated>
    
    
    <summary type="html">&lt;p&gt;本文为个人安装CDH时记录，不具普适性，仅供参考。建议对比官方文档阅读。&lt;/p&gt;</summary>
    
    
    
    <category term="大数据" scheme="https://linshenkx.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="CDH" scheme="https://linshenkx.github.io/tags/CDH/"/>
    
  </entry>
  
  <entry>
    <title>oracle_logminer学习和实践笔记</title>
    <link href="https://linshenkx.github.io/oracle_logminer/"/>
    <id>https://linshenkx.github.io/oracle_logminer/</id>
    <published>2020-09-24T09:03:16.000Z</published>
    <updated>2021-09-01T08:02:17.790Z</updated>
    
    
    <summary type="html">&lt;p&gt;Oracle LogMiner是Oracle公司从产品8i以后提供的一个实际非常有用的分析工具，使用该工具可以轻松获得Oracle 在线/归档日志文件中的具体内容，特别是该工具可以分析出所有对于数据库操作的DML和DDL语句。该工具特别适用于调试、审计或者回退某个特定的事务。&lt;/p&gt;</summary>
    
    
    
    <category term="后端开发" scheme="https://linshenkx.github.io/categories/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/"/>
    
    
    <category term="oracle" scheme="https://linshenkx.github.io/tags/oracle/"/>
    
    <category term="logminer" scheme="https://linshenkx.github.io/tags/logminer/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes应用中使用TLS(SSL)证书的两种方法及实践</title>
    <link href="https://linshenkx.github.io/kubernetes-tls-ssl-certificates/"/>
    <id>https://linshenkx.github.io/kubernetes-tls-ssl-certificates/</id>
    <published>2020-08-27T15:55:09.000Z</published>
    <updated>2021-09-01T08:02:17.787Z</updated>
    
    
    <summary type="html">&lt;p&gt;在k8s应用注入自签发的TLS/SSL证书有两种思路：1.使用certificates.k8s.io API 进行签发。2. 直接利用自己的CA证书进行签发。一般推荐第二种方法，本文记录了两种方法的完整实践并最后将其转换为JAVA的使用格式。&lt;/p&gt;</summary>
    
    
    
    <category term="Kubernetes" scheme="https://linshenkx.github.io/categories/Kubernetes/"/>
    
    
  </entry>
  
  <entry>
    <title>Xloggc实践（JVM1.8及之前）</title>
    <link href="https://linshenkx.github.io/Xloggc/"/>
    <id>https://linshenkx.github.io/Xloggc/</id>
    <published>2020-08-19T16:55:34.000Z</published>
    <updated>2021-09-01T08:02:17.789Z</updated>
    
    
    <summary type="html">&lt;p&gt;Java服务器调优免不了要对gc日志进行分析，我一般是上传gc日志文件到GCEasy进行处理的，上传的文件有大小限制。另外默认的gc日志打印还会存在重启后丢失的问题。综上，我们希望gc日志文件在不能丢失（但允许超过一定时间或大小被清理掉）的情况下控制gc日志的大小或者按时间切割，即像Java日志框架那样的效果。Java9对jvm的日志系统进行了比较大的升级，可以比较好的实现这些需求，但大部分服务端的Java软件还只支持Jdk8，本文记录作者自己的相关配置。&lt;/p&gt;</summary>
    
    
    
    <category term="后端开发" scheme="https://linshenkx.github.io/categories/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/"/>
    
    
    <category term="jvm" scheme="https://linshenkx.github.io/tags/jvm/"/>
    
  </entry>
  
  <entry>
    <title>kafka动态调整副本因子replication.factor及json生成脚本</title>
    <link href="https://linshenkx.github.io/kafka_replication_factor/"/>
    <id>https://linshenkx.github.io/kafka_replication_factor/</id>
    <published>2020-08-19T01:54:58.000Z</published>
    <updated>2021-09-01T08:02:17.796Z</updated>
    
    
    <summary type="html">&lt;p&gt;kafka默认的副本因子default.replication.factor是1，即无额外副本，如果在创建topic时没有指定副本数，则无高可用性。&lt;/p&gt;</summary>
    
    
    
    <category term="大数据" scheme="https://linshenkx.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="kafka" scheme="https://linshenkx.github.io/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>空间索引 S2 学习指南及Java工具类实践</title>
    <link href="https://linshenkx.github.io/google_spatial_search_s2/"/>
    <id>https://linshenkx.github.io/google_spatial_search_s2/</id>
    <published>2020-04-28T17:23:21.000Z</published>
    <updated>2021-09-01T08:02:17.793Z</updated>
    
    
    <summary type="html">&lt;p&gt;geohash对于大区域查询表现极不良好，经调研测试，改用google的s2。因为涉及的资料、工具较多，特此记录，以备后用。&lt;/p&gt;</summary>
    
    
    
    <category term="后端开发" scheme="https://linshenkx.github.io/categories/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/"/>
    
    
    <category term="s2" scheme="https://linshenkx.github.io/tags/s2/"/>
    
  </entry>
  
  <entry>
    <title>HBCK2修复RIT实践笔记</title>
    <link href="https://linshenkx.github.io/hbck2_rit/"/>
    <id>https://linshenkx.github.io/hbck2_rit/</id>
    <published>2020-04-15T17:40:39.000Z</published>
    <updated>2021-09-01T08:02:17.794Z</updated>
    
    
    <summary type="html">&lt;p&gt;本文记录了作者使用HBCK2工具对线上HBase发生RIT状态的处理，仅供参考，若有疵漏，还望指正。&lt;br&gt;网络上关于HBCK2的文章很少，基本都是复制粘贴自田竞云(小米)的这一篇：&lt;a href=&quot;https://mp.weixin.qq.com/s/GVMWwB1WsKcdvZGfvX1lcA?spm=a2c4e.11153940.blogcont683107.11.49d762a815MegW&quot;&gt;HBase指南 | HBase 2.0之修复工具HBCK2运维指南&lt;/a&gt;&lt;br&gt;事实上这一篇文章介绍得也已经很详细了。这里只是做一些实践上的补充说明。&lt;/p&gt;</summary>
    
    
    
    <category term="大数据" scheme="https://linshenkx.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    <category term="HBASE" scheme="https://linshenkx.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/HBASE/"/>
    
    <category term="bug" scheme="https://linshenkx.github.io/categories/bug/"/>
    
    
    <category term="hbase" scheme="https://linshenkx.github.io/tags/hbase/"/>
    
    <category term="debug" scheme="https://linshenkx.github.io/tags/debug/"/>
    
  </entry>
  
  <entry>
    <title>深入解析Spring使用枚举接收参数和返回值机制并提供自定义最佳实践</title>
    <link href="https://linshenkx.github.io/spring_enum/"/>
    <id>https://linshenkx.github.io/spring_enum/</id>
    <published>2019-01-14T01:54:10.000Z</published>
    <updated>2021-09-01T08:02:17.791Z</updated>
    
    
    <summary type="html">&lt;p&gt;Spring对应枚举传参/返回值默认是用字面量实现的（实际情况更复杂），而《阿里巴巴Java开发手册》规定接口返回值不可以使用枚举类型（包括含枚举类型的POJO对象），为此，本文探究了Spring内部对枚举参数的传递和处理机制，并提供了一套自定义方案。&lt;/p&gt;</summary>
    
    
    
    <category term="后端开发" scheme="https://linshenkx.github.io/categories/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/"/>
    
    
    <category term="Spring" scheme="https://linshenkx.github.io/tags/Spring/"/>
    
  </entry>
  
  <entry>
    <title>SpringSecurity5.0的DelegatingPasswordEncoder详解</title>
    <link href="https://linshenkx.github.io/DelegatingPasswordEncoder/"/>
    <id>https://linshenkx.github.io/DelegatingPasswordEncoder/</id>
    <published>2018-05-07T06:30:32.000Z</published>
    <updated>2021-09-01T08:02:17.788Z</updated>
    
    
    <summary type="html">&lt;p&gt;本文参考自Spring Security 5.0.4.RELEASE  的官方文档,结合源码介绍了DelegatingPasswordEncoder,对其工作过程进行分析并解决其中遇到的问题.包括&lt;code&gt;There is no PasswordEncoder mapped for the id &amp;quot;null&amp;quot;&lt;/code&gt;的非法参数异常的正确处理方法&lt;/p&gt;</summary>
    
    
    
    <category term="后端开发" scheme="https://linshenkx.github.io/categories/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/"/>
    
    
    <category term="Spring" scheme="https://linshenkx.github.io/tags/Spring/"/>
    
  </entry>
  
</feed>
